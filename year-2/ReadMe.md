EXAM:

Confirmation that each task is marked separately with nothing carrying forward – for example,  if a learner creates a
design which might be fundamentally flawed, or that they end up not following in the next task, there is no penalty in
those later tasks. There is also no preference to how the task is delivered – so they could create a website, an app,
whatever,  as long as they meet the brief, again, no marks are carried forward so they could design one system but produce
something totally different. 

Confirmation that every year the tasks will be the same and the scenario is the only thing that changes.

Even though they are allocated more hours in task 2 than they are in task 1, task 1 has a higher 
weighting – the analysis is where the higher marks are in this section

Part of the marks are awarded for the documentation being able to be followed by a different 
person (I.e., design docs should be detailed enough that someone else could create the system) and 
understandable by non-technical audiences.

Document everything – they will receive marks where they clearly explain what they have done.
I.e., the conventions they have used should be put in a section in the documentation that clearly 
states, “These are the conventions used…”, Document any iterative testing throughout etc. 

Pseudocode attracts higher marks than flowcharts.

Pearson advise them to find a mark scheme and then cross off all the bullet points in it in the 
exam– they specifically said that they are available online and they have access to the internet. 

AI/Chat GPT – Pearson do not encourage the use of it, but students can use the code it generates
if they manipulate it to fit the purpose of the assessment. Essentially, don’t just copy in AI generated 
code. They can also use GitHub and watch tutorials etc (as we know), they cannot take work home. Centre 
must manage/monitor access to the internet, but Pearson recognise that it’s unclear how we are supposed 
to monitor/manage it

Headphones in the assessments are allowed
